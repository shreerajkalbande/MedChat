# 🩺 MedChat – Medical Diagnosis Chatbot

![Made with Python](https://img.shields.io/badge/Made%20with-Python-3776AB?style=for-the-badge&logo=python&logoColor=white)
![Frontend: HTML/CSS](https://img.shields.io/badge/Frontend-HTML%2FCSS-f06529?style=for-the-badge&logo=html5&logoColor=white)
![Backend: Flask](https://img.shields.io/badge/Backend-Flask-6e6e6e?style=for-the-badge&logo=flask&logoColor=white)
![MIT License](https://img.shields.io/badge/License-MIT-yellow.svg?style=for-the-badge)


An advanced chatbot for preliminary medical diagnosis using open source **Mistral LLM**, **LangChain**, and **PineconeDB**. It supports:
- Symptom-based queries  
- Analysis of user-inputted test results  
- Probability-based disease predictions

The backend is built using **Flask**, ensuring lightweight and responsive deployment.

---

## 🚀 Features

- 🔍 Retrieval-Augmented Generation (RAG) powered by **open-source Mistral LLM**
- ⚕️ Ingests and embeds medical knowledge from the Gale Encyclopedia of Medicine using **Hugging Face** models
- 📦 Stores vector embeddings in **Pinecone** for fast similarity-based retrieval
- 🧠 Context-aware responses generated by combining the user query with relevant medical context
- 🌐 Simple and clean frontend built with **HTML/CSS**
- 🐳 Fully containerized using **Docker**
- 🔁 CI/CD pipeline integrated for automatic deployment and testing

---

## 🧱 Tech Stack

| Layer          | Tools/Frameworks Used                                     |
|----------------|-----------------------------------------------------------|
| **Frontend**   | HTML, CSS                                                 |
| **Backend**    | Python, Flask                                             |
| **RAG Engine** | LangChain, Pinecone, Mistral LLM (via Hugging Face)       |
| **Vector DB**  | Pinecone (FAISS alternative for production)               |
| **Container**  | Docker                                                    |
| **Deployment** | CI/CD pipeline                                            |

---

## 🛠️ How It Works

1. 📘 **Embedding Medical Data**  
   - Medical content is embedded into vector representations using Hugging Face transformers.
   - These embeddings are stored in Pinecone for fast retrieval.

2. 🔎 **Query Processing**  
   - A user submits a symptom or medical test-related query.
   - LangChain fetches relevant context using vector similarity from Pinecone.

3. 🧾 **LLM-Based Answering**  
   - Mistral LLM uses retrieved documents and user input to generate medically coherent answers.

4. 🔁 **Session Handling**  
   - Conversations are state-aware using LangChain's memory components.

---

## 🧪 Setup & Run

1. **Clone the repo**
   ```bash
   git clone https://github.com/shreerajkalbande/MediChat.git
   cd medical-chatbot
   ```

2. **Create a Conda Environment(Optional)**
   ```bash
   conda create -n medibot
   conda activate medibot
   ```

3. **Install dependencies**
   ```bash
   pip install -r requirements.txt
   ```

4. **Create the .env file in `/`**
   ```md
   PINECONE_API_KEY=xxxx
   HUGGINGFACEHUB_API_KEY=xxxx
   ```

5. **Create vector embeddings (only once)**
    ```bash
    python store_index.py
    ```

6. **Run the app**
   ```bash
   python app.py
   ```

The Flask app will run on http://localhost:8080

---

## 🐳 Docker (Optional)

```bash
docker build -t medibot .
docker run -p 5000:5000 medibot
```

---

## 📄 License
This project is licensed under the MIT License.

---

## 🤝 Contributions
Feel free to fork, raise issues, or submit PRs to improve this project!

---

## 📝 Author
Shreeraj Kalbande | IIT Kharagpur CSE

Email: [shreerajkalbande25@gmail.com]
